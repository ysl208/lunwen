Programming robots for general purpose applications is extremely challenging due to the great diversity of end-user tasks.
Not only is it generally left up to robotics experts, but end-user programming solutions are often limited to teaching robots predefined actions for specific tasks that cannot be reused.
Our research argues for letting end-users teach robots primitive or \textit{atomic} actions from scratch that can be reused with task planners for previously unseen problems.
In this way, we delegate the logical reasoning process of finding a solution to task planners and facilitate the robot programming process, while maintaining the generalisability of taught actions.
This part of the thesis contains our contributions.
We first present iRoPro, an interactive Robot Programming framework and discuss its theoretic components.
We then discuss the research methodology used in this thesis which resulted in the contributions presented in the remaining chapters.

iRoPro allows end-users to teach a robot primitive actions from scratch that can be reused with a task planner.
%a goal-oriented behaviour and 
The framework consists of the following three components (\fig{fig:framework}): 
\begin{enumerate}
	\item[A.]{Programming by Demonstration: user teaches the robot primitive actions by demonstration.}
	\item[B.]{Automated Planning: robot uses taught actions with a planner to generate solutions to achieve a task goal.}
	\item[C.]{Retro-active Loop: user refines taught actions in case of ambiguities.}
\end{enumerate}
Similar to previous work (\cite{perzylo2016intuitive}), the user is provided with a graphical interface (GUI) that abstracts from the underlying modeling language for automated planning.
For each step, the user interacts with the GUI to navigate between the steps to teach new actions by kinesthetic demonstration, modify action conditions, define new planning problems, and have the robot autonomously solve and execute automatically generated plans in real-time.
In the following sections, we discuss each component in more detail. 
%We refer the reader to a video of the framework: \texttt{https://youtu.be/DTm2YjiSNQM}
%Using this knowledge base, the user can define a planning problem, for which the robot will generate a plan. 

\begin{figure}[!h]
	\centering
	\includegraphics[width=\linewidth]{figures/framework.png}
	\caption{An overview of the iRoPro (interactive Robot Programming) framework: 1. the user teaches primitive actions by demonstration 2. the robot reuses these with an automated planner, to generate an action sequence to achieve a goal.
After an unsuccessful robot execution, the user can refine the taught action models (dotted lines indicate user actions, solid lines indicate robot actions).}
	\label{fig:framework}
\end{figure}

\section{Programming by Demonstration: teaching actions}
%Our approach aims at providing end-users with an intuitive way of 
Teaching robots atomic actions consists of learning both \textit{how} and \textit{when} an action should be applied, \ie the low-level (\sect{ssec:lowlevel}) and high-level representations (\sect{ssec:highlevel}).
We consider an action that consists of both low- and high-level representations as an \textit{action model}.
Programming by demonstration (PbD) techniques provide end-users with an intuitive way to teach the robot action models. %generally consist of an iterative process.
In keyframe-based PbD (\cite{akgun2012keyframe,alexandrova2014robot}) actions are represented as a sparse sequence of keyframes that can be connected to perform a skill.
%gripper states (open/close) and end-effector poses relative to perceived objects or to the robot's coordinate frame.
Low-level actions can be learned from multiple demonstrations (\cite{niekum2012learning}) or a single demonstration, where poses are assigned heuristically and corrected by the user if needed (\cite{alexandrova2014robot}).
Dynamic Movement Primitives (\cite{pastor2009learning}) or mixture models (\cite{calinon2007incremental}) learn actions from entire motion trajectories but generally require multiple demonstrations (\cite{abdo2013learning}).
\cite{ahmadzadeh2013visuospatial} generates trajectories by extracting three key points that represent rest, pick and place of an object.

The user can teach multiple low-level manipulation actions and discriminate between them by associating different high-level conditions that specify \textit{when} the robot should use them (\eg actions using claw or suction grippers).
In iRoPro, high-level actions are represented similar to planning operators in task planning (\sect{subsec:Classical planning problem}), where an action is represented as a tuple $o = (\text{name}(o), \text{precond}(o),$ $\text{effect}(o))$.
Preconditions and effects are represented in terms of predicates, \eg object properties, that describe the current state of the world.
The robot uses a perception system (\eg SIFT (\cite{ahmadzadeh2015learning})) or a database of object features (\cite{mason2011robot})) that automatically recognises object properties such as type, position, or spatial relation relative to other objects.
When the user demonstrates an action, such as pick-and-place of a cube, %\texttt{(move cube A B)}.
it results in a change in the world state, \eg the cube's position from a position A to B.
The robot observes the world state before and after the action demonstration, and infer relevant predicates for preconditions and effects to build an action model. %, expressed in a symbolic planning language.% (Fig. \ref{fig:action} bottom).
Predicates can be inferred from observing what has changed or what stayed the same in the state of the world.
Feature-based algorithms, such as k-means clustering (\cite{mollard2015robot,abdo2013learning}), can be used to learn high-level action conditions from multiple demonstrations.
Existing PbD approaches try to teach the robot from a small number of demonstrations (\cite{orendt2016robot,abdo2013learning}), but require at least five contextually different ones.
%To learn object manipulation tasks, the robot perceives the initial world state before %(\textit{precondition}) and after the action demonstration and infers the high-level conditions (\cite{ahmadzadeh2015learning}).
%(\textit{effects}). 
In iRoPro, we propose an interactive programming approach, where the user can directly modify and correct the learned action models via the graphical interface.
Thus, the robot can learn a new action from a single demonstration with the user acting as the expert to correct inferred conditions.
Finally, the user validates the learned action model or provides additional demonstrations to refine the low- or high-level representations.
%The robot learns from multiple demonstrations to generalise trajectories and high-level conditions.
%In the framework, we assume that the learned action trajectory is independent of the trajectory performed by the teacher.

%Note that we do not address the perception problem in this paper. 
%In our experiments, we implemented a simple python algorithm with integrated functionalities of the Robot Operating System (ROS) (\cite{quigley2009ros}), to detect and move objects, based on their colour.

%Table \ref{tab:action-model} shows the states of the demonstrated action and the generalised action model. 
%The generalised operator is automatically translated into a symbolic representation, allowing the creation of a planning domain, without the need for any programming knowledge.


\section{Automated Planning: reusing actions}\label{sec:AP}
In the PbD step, the robot learned action models including the high-level representation that allows it to be used with a planner. 
Automated planners are used to generate solutions to solve complex problems (\chapt{chap:Sota-AP}).
Various planners have been used for robotic task planning, such as the STRIPS planner (\cite{she2014teaching}), Metric-FF (\cite{cubek2015high}), fast downward planner (\cite{abdo2013learning}). 
Given a description of a planning \textit{domain}, \ie object types, predicates, and high-level actions, we can define a planning \textit{problem} with an initial state and a desired goal state to achieve. 
The planner generates an optimal action sequence, or \textit{plan}, which guarantees the transition from initial state to the goal state. 
%Automated planners try to model the robot's strategies, when operating in diverse environments \cite{ghallab2004automated}.
%ught actions are reused with existing task planners by translating them into PDDL (\citet{mcdermott1998pddl}). 
To facilitate the programming process, a partial PDDL domain including a set of object types and predicates can be integrated that the robot is able to recognise with its perception system.
The user completes the PDDL domain by creating new action models and correcting preconditions and effects via the user interface.
% and manually adding custom types and predicates via the user interface.

The user creates a new planning problem by detecting the initial world state and defining the goal states to achieve.
The initial world state is automatically recognised by the robot using the same perception system as in the PbD phase. 
The user can modify the detected world states and enter predicates that describe a goal for the robot to achieve.
Given the PDDL domain and problem entered by the user, the automated planner generates a plan, consisting of an ordered action sequence for the robot to execute. 
The user can verify the generated plan and have the robot execute it in real life.
If no plan is generated or if the plan seems incorrect, users can modify the taught actions, initial or goal states and relaunch the planner.


\section{Retro-active Loop: refining actions}
The retro-active loop allows the user to revisit and correct created action models.
%Generating a plan under different initial states allows the user to test the created action models.
It is likely that the generated plan does not produce the desired outcome, especially if the context of the planning problem is different to that of the initial demonstration (\eg different object types or positions).
To minimise the user's programming process, taught actions should be generalised and reused as much as possible.
Instead of creating new action models for each problem, the user should revisit and modify existing ones so that they are used correctly by the planner.
Thus, the application to a new context is an important step to test the generalisability of action models.
If the generated plan is incorrect, there are several possible causes:
\begin{itemize}
	\item \textbf{Object types:} they dictate what objects an action can be applied to. If they do not match those of the current planning problem, actions would not be considered by the planner (\eg pick-and-place was only defined for cube objects but not other types).
	\item \textbf{Preconditions:} this can lead to suboptimal or non-existing solutions as the planner makes incorrect assumptions on the allowed usage of taught actions (\eg trying to use a suction gripper on a pointed object).
	\item \textbf{Effects:} similar to preconditions this can lead to suboptimal or non-existing solutions as the world state is not correctly updated after the action execution (\eg a position is still considered free when it is occupied).
	\item \textbf{Initial world state:} if the initial world state is incorrect the planner could consider certain actions as invalid due to preconditions that are required to apply them.
	\item \textbf{Goal states:} it is important to define only the main states that need to be achieved, rather than consequences or intermediate steps to achieve them. Furthermore, contradicting goal states can lead to non-existing plans (\eg an object is on a position and the position is free are states as goal states).
\end{itemize}

Knowledge engineering tools (\sect{subsec:Knowledge Engineering}) facilitate this process of modifying action models used for automated planners.
They often provide useful functionalities for dynamic testing, model checking and visualisation (\cite{simpson2007planning}), but most tools require expertise in automated planning or common software engineering concepts.
%where the quality of the models generated does not depend on the user's expertise.
In this thesis we argue that the proposed robot programming process does not require this expertise and can be learned easily by users with different educational backgrounds.


\section{Methodology}
The contributions in this thesis were constructed using both quantitative and qualitative research methodologies.
Our general approach follows the design wheel\footnote{\url{http://www.designingourtomorrow.com/business/CDA_map/}} consisting of successive cycles of `Explore', `Create', `Evaluate' and `Manage' phases (\fig{fig:designwheel}).
Our contributions represent the following stages:
\begin{enumerate}
	\item {\textbf{Pre-Experiments: }We start by conducting initial qualitative user experiments to investigate how end-users adopt basic concepts in Automated Planning and Programming by Demonstration.
	We are particularly interested in the difficulties they encounter when learning and applying automated planning concepts as they can be considered in the iRoPro system implementation.
	For this we create an initial prototype used for simulating iRoPro with the Wizard-of-Oz technique (\chapt{chap:Pre-Experiments}).
	}
	\item {\textbf{Goal-oriented Programming: }We then explore goal-oriented end-user programming approaches by allowing users to simultaneously teach the robot actions and goals by demonstration.
	For this we implement a system that includes learning new actions and goal inference and evaluate it in an online user study on Amazon Mechanical Turk (\chapt{chap:OrganisingTasks}).}
	\item {\textbf{End-to-End System Implementation:}Taking the existing work as a basis, we implement iRoPro on a Baxter robot to allow simultaneous teaching of low- and high-level actions by demonstration.
	The end-to-end system includes a graphical interface that users interact with directly to program the robot (\chapt{chap:Implementation}).}
	\item {\textbf{Post-Experiments: }Finally, we conclude this thesis work by conducting further user experiments using the implemented system.
		We compare user groups with different educational backgrounds and investigate their performance on how they learn and use the system for programming the robot.
		These experiments allow us to compare draw a comparison with our initial qualitative experiments conducted at the start of this thesis work and evaluates the proposed framework with real users (\sect{sec:quanteval})}
\end{enumerate}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/designwheel}
	\caption{The design wheel consists of successive cycles of `Explore', `Create', `Evaluate' and `Manage' phases. TODO}
	\label{fig:designwheel}
\end{figure}
