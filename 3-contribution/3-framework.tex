In \cite{liang2017framework}, we designed a 3-step robot programming framework. Figure \ref{fig:framework} illustrates the following steps: 
\begin{enumerate}
	\item[A.]{Programming by Demonstration: user demonstrates atomic actions and teaches symbolic action models, in terms of preconditions and effects.}
	\item[B.]{Automated Planning: robot uses action models to generate an action sequence to achieve a goal.}
	\item[C.]{Retro-active Loop: user refines the learned action models in case of ambiguities.}
\end{enumerate}
In the following sections, we discuss each step in more detail. 
%We refer the reader to a video of the framework: \texttt{https://youtu.be/DTm2YjiSNQM}
%Using this knowledge base, the user can define a planning problem, for which the robot will generate a plan. 

\section{Programming by Demonstration: teaching action models}
Programming by demonstration (PbD) techniques generally consist of an iterative process. The user demonstrates an atomic action, such as moving a cube from an initial position A to a final position B \texttt{(move cube A B)}. An action execution results in a change in the world state, such as the cube's position. The robot observes the changes before and after the action demonstration (Fig. \ref{fig:action} top), and extracts the relevant preconditions and effects to build a generalised action model, expressed in a symbolic planning language (Fig. \ref{fig:action} bottom). The user validates the learned action model, and provides additional demonstrations if necessary.

The robot learns from multiple demonstrations to generalise trajectories and high-level conditions. In the framework, we assume that the learned action trajectory is independent of the trajectory performed by the teacher. Dynamic Movement Primitives (DMP) can cope with the generalisation of a demonstrated trajectory \cite{pastor2009learning}. To learn high-level conditions, the robot uses a perception system (e.g. SIFT \cite{ahmadzadeh2015learning} or a database of object features \cite{mason2011robot}) that recognises object properties in the state of the world. 
%Note that we do not address the perception problem in this paper. 
In our experiments, we implemented a simple python algorithm with integrated functionalities of the Robot Operating System (ROS), to detect and move objects, based on their colour. 
Feature-based algorithms, such as k-means clustering \cite{mollard2015robot}, can be used to generalise over high-level conditions.

%Table \ref{tab:action-model} shows the states of the demonstrated action and the generalised action model. 
%The generalised operator is automatically translated into a symbolic representation, allowing the creation of a planning domain, without the need for any programming knowledge. 
Existing PbD approaches try to teach the robot from a small number of demonstrations \cite{orendt2016robot,abdo2013learning}. We propose an interactive learning approach, where the user can directly modify the learned action models using a user-interface.

  \begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\linewidth]{figures/schema-logic}
	\caption{Action model representation of a move action in terms of preconditions and effects: demonstrated action model for a cube (top), and generalised action model for any object, variables are prefixed with `?' (bottom).}
	\label{fig:action}
\end{figure}

\section{Automated Planning: using action models}\label{sec:AP}
The robot uses the learned symbolic action models in combination with an automated planner to achieve user-defined goals. Automated planners try to model the robot's strategies, when operating in diverse environments \cite{ghallab2004automated}.
Figure \ref{fig:planning-permutation} illustrates an example of a planning problem. Given a description of the world state, i.e. objects, types, properties (Fig. \ref{fig:planning-permutation}a,b), a set of possible atomic actions, and a goal state (Fig. \ref{fig:planning-permutation}d), a planner generates a sequence of actions (Fig. \ref{fig:planning-permutation}c), which guarantees the transition from the initial world state to the goal state. Predicates are used to describe actions and object properties, such as \textit{``red cube is at position A"}: they can be \textit{instantiated} \texttt{(at redCube A)} or \textit{generalised} \texttt{(at ?cube ?posA)}, such that variables are prefixed with `?'.

To allow a correct transition between different states of the world, actions are defined in terms of {preconditions} and {effects} (Fig. \ref{fig:action}). For a move action \texttt{(move cube A B)}, preconditions are the states required to perform the action  \texttt{(at cube A)}, and effects are the states obtained after the action \texttt{(at cube B)}. Classical planning algorithms use the Planning Domain Definition Language (PDDL) \cite{ghallab2004automated} as their standard encoding language, which extends the STRIPS \cite{fikes1971strips} formalism with greater expressivity, such as type structures (Fig. \ref{fig:planning-permutation}b). An example of a generalised move action in PDDL, for moving an arbitrary cube, from one position to another, is given below (\texttt{?cube}, \texttt{?posB}, \texttt{?posA} are variables for cube, initial position, final position respectively):

\begin{small}
	\begin{verbatim}
	(:action move
	:parameters (?cube ?posA ?posB)
	:precondition (and (at ?cube ?posA)
	(empty ?posB))
	:effect    (and (at ?cube ?posB)
	(empty ?posA)))  \end{verbatim}
\end{small}

The initial world state is automatically recognised by the robot using the same perception system as in the PbD phase. 
%The automated planner generates a plan, consisting of an ordered action sequence for the robot to execute. 
The user can change the initial object configuration of the world state, and enter an arbitrary goal, that can be achieved using the taught action models. If the user changes the goal, a new action sequence is generated by the planner. Generating a plan under different initial states allows the user to test the created action models. There exist various planners that can be used for symbolic planning with robots: Metric-FF (\cite{cubek2015high}), or a fast downward planner (\cite{abdo2013learning}). 
\begin{figure}[t]
	\centering
	\includegraphics[width=8.5cm]{figures/planning-permutation}
	\caption{Definition of a planning problem (a) properties describing the initial world state (b) object names and their types (c) instantiated actions (d) properties describing the goal state.}
	\label{fig:planning-permutation}
\end{figure}


\section{Retro-active Loop: refining action models}
The execution to a new context is an important step to test the taught action models. It is likely that the execution of the plan does not produce the desired outcome, especially if the plan is executed in a context different to the demonstration (e.g. different object colour or position). Missing preconditions or effects for an action model can lead to suboptimal or non-existing solutions and will need to be corrected by the user. The retro-active loop allows the user to revisit the created action models. Knowledge engineering tools provide a user-interface to facilitate this process of modifying action models used for automated planners. They often provide useful functionalities for dynamic testing, model checking and visualisation \cite{simpson2007planning}, where the quality of the models generated does not depend on the user's expertise. 