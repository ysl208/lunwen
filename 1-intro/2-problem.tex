
\section{Problem Statement}
In this thesis we argue for teaching robots primitive actions, instead of entire action sequences, and delegating the logical reasoning process of finding a solution to task planners.
Most solutions to teach the robot new actions assume a finite list of primitive actions that these actions are based on.
However, to date, there is no database of general purpose primitive actions and whether a finite set can list all necessary motions is questionable (\cite{billard2016learning}).
While previous work has addressed integrating task planning with robotic systems (\citet{abdo2013learning,cashmore2015rosplan}), enabling end-users to teach new actions from scratch that can be reused with task planners has not been addressed and is extremely challenging. 
The system should allow efficient programming of both \textit{how} an action is performed (low-level action) and \textit{when} it can be applied (high-level action), while being able to generalise both aspects to previously unseen scenarios. 
Furthermore, the system should provide an intuitive interface that allows end-users to reuse the taught actions together with a task planner, that is generally handled by domain experts.
To that end, we must create a framework that combines the following aspects:
\begin{itemize}
	\item \textbf{Programming by demonstration:} the user should be able to teach the robot primitive actions from scratch, including both \textit{how} and \textit{when} to perform the action, without writing explicit code,
	\item \textbf{Automated planning:} taught actions should be part of a planning domain that can be used by task planners to generate solutions,
	\item \textbf{Intuitive robot programming:} the user interface, planning domain and robot programming process need to be intuitive enough for users to understand easily and to allow them to navigate on their own in order to customise the robot to their specific tasks.
\end{itemize}

In other words, the system should enable the user to program the robot in an intuitive way, \eg by demonstration, and thereby construct 
%a knowledge base, consisting of a domain model (the environment that the robot interacts with) and 
reusable low- and high-level actions for the robot to accomplish previously unseen tasks.
A functioning real-world system requires solutions in perception (\eg object identification), motion planning (\eg manipulation, navigation, safety),  cognitive robotics (\eg action learning, task planning) and humanâ€“robot interaction (\eg multi-modal interaction and teacher feedback). 
The integration of all aspects into a real-time system is a major challenge.
In this thesis we address this with the final goal to create a working end-to-end system for end-user robot programming.
% and provide partial solutions for the other areas.
We address the following research question:
\begin{center}
	\textit{Can non-robotics users teach a robot actions from scratch that it can reuse to autonomously solve previously unseen problems?}
\end{center}

With the focus on cobotic environments, we further investigate the difficulties encountered by end-users, when faced with PbD and Automated Planning concepts for the first time. 
We evaluate our approach with pick-and-place robots, addressing assembly and packaging tasks, two of the most common application types in manufacturing facilities (\cite{pickandplace}).
% limitations 
%We need to consider the limitations: limited resources, lack of programming knowledge and time to train operators.
%, rather than atomic actions that can be reused independently 

% semantics for application to new context
%A robot that learns how to arrange items on a desk may have to plan the order of handling objects in another way than originally demonstrated by the teacher.
%Thus, it does not suffice for the robot to replicate the demonstrated movement, but it needs to understand and interpret the teacher's intention so that it can apply the action to different scenarios.
%
%In other words, given a user-defined goal, the robot should generate and execute the right action sequence to obtain it.

% example domain 
%The domain model would consist of a table with a finite number of objects and limited positions, as well as actions consisting of pick, place and move. 
%Possible goals could be to stack the objects by size (similar to the Tower of Hanoi problem) or to arrange the objects in a certain order. 
%Our framework should enable the user to teach the robot by demonstration all action models needed, including their relevant preconditions and effects. 
%Once the action models have been created, the inbuilt automated planner can generate an action sequence to achieve any goal within the domain. 

%Hence, we address two common situations, where reprogramming is required: 
%\begin{itemize}
%\item A new subtask needs to be included in the task execution, \eg the robot knows how to place objects from any position on the table into a basket, but should additionally rotate them before placing them;
%\item All subtasks are available but the ultimate goal has changed, \eg the order of placing the objects has been changed.
%\end{itemize}


\section{Summary of contributions}
%\subsection{Thesis statement}
%Non-expert users can program a robot to complete a set of tasks by teaching it atomic actions by demonstration and correctly assigning them preconditions and effects that can be used with an automated planner to solve more complex problems.
%\todo{2-3 key research ideas/questions}
%In this thesis we propose a robot programming framework that allows human operators to:
%\begin{itemize}
%	\item teach the robot action models in a comprehensive automated planning representation, translated into PDDL, and
%	\item enable it to use the learned action models to be controlled with a goal-oriented approach based on automated planning techniques.
%\end{itemize}

This thesis contributes mainly to the fields of end-user robot programming and human-robot interaction, by proposing and implementing an end-user robot programming framework and conducting relevant user studies.
The contributions can be summarised as follows:
\begin{itemize}
	\item {We propose iRoPro, an end-user robot programming framework that combines PbD and Automated Planning techniques, where the robot learns new actions from user demonstrations that it can reuse with a task planner. %(\cite{liang2017framework}).
	The robot programming process consists of the following steps:
	\begin{enumerate}
		\item the user teaches the robot new actions by kinesthetic demonstration, where the robot learns both low- and high-level action representations,
		\item the robot uses these actions with a task planner to generate solutions to user-defined problems,
		\item the user can either have the robot execute the generated solution or revisit the taught actions via the graphical interface to refine them.
	\end{enumerate}
%	\textbf{Research question:} \textit{Can end-users teach the robot actions and associated conditions using PbD that can be used by a planner to solve a user-defined task?}
}

    \item {User study 1: Experimental findings on issues encountered when non-robotics end-users are introduced to AI planning concepts and tasked to use a symbolic planning language to describe planning domains and problems to the robot. 
    	We evaluate the user's ability to construct action in terms of preconditions and effects and show that users with little to no programming experience can easily learn and use symbolic planning languages.\\% (\cite{liang2017evaluation}).\\
    	\textbf{Research question:} \textit{How do non-expert users adopt the automated planning language with its action model representation?}}

    \item {User study 2: Experimental findings on user acceptance of the proposed framework. Using the Wizard-of-Oz technique, users were tasked to teach a robot actions by kinesthetic demonstration and assign conditions that can be used for automated planning.\\
    	\textbf{Research question:} \textit{Can users teach a robot action models for automated planning using the robot programming framework?}}

	\item {Goal-oriented robot programming: We present a goal-oriented robot programming system for shelf organisation tasks using PbD and an graphical user interface. %(\cite{liang2018simultaneous}).
		The system allows the robot to learn and execute organisation tasks from user input to simultaneously teach goals and actions by demonstration.
		The robot learns both \textit{what} and \textit{how} to perform a task using PbD and a goal inference model.
		We evaluated user teaching strategies with experiments on Amazon Mechanical Turk and compared their performance to eight benchmark strategies.\\
%		\textbf{Research question:} \textit{Can users teach the robot an organisation task using PbD and goal inference and what teaching strategies do users prefer?}
}

	\item {We implement iRoPro as an end-to-end system on a Baxter research robot that 
		\begin{enumerate}
			\item allows simultaneous teaching of low- and high-level actions from a single demonstration, 
			\item includes a user interface for action creation with condition inference and modification, and
			\item allows creating and solving previously unseen problems using a task planner for the robot to execute in real-time.
		\end{enumerate}
	The implementation includes a graphical interface, which allows the user to teach new actions by kinesthetic demonstration, modify action conditions, define new planning problems for the robot to solve and execute the plan in real-time.
	This system enables end-users to program robots from scratch, without writing code.%, therefore maximising the generalisability of taught actions with minimum programming effort.
}

	\item {User study and system evaluation:
	We demonstrate iRoPro's capability to generalise primitive actions on six benchmark tasks that are programmed and executed on the Baxter robot.
	We empirically investigate the usability of our system and validate its intuitiveness through a study with 21 users of different educational backgrounds and programming levels.
%and perform an analysis on both quantitative and qualitative data .
	To better understand user teaching strategies, we split participants into two control groups, with and without automatic condition inference, and showed that users in both groups can easily learn and use the system.}
	
	
\end{itemize}
