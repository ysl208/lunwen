\section{Discussions and Relations to Present Work}
Manual programming systems provide direct control over the robot's behaviour but require users with programming expertise and high programming time and effort for debugging and testing.
The solutions are often task-specific and cannot be changed easily by end-users.
Automatic programming systems require significantly less effort when it comes to the programming process. 
However, DL solutions generally need large amounts of training data that is relevant for the desired application.
RL solutions can be time-consuming as they require the robot to explore the environment and collect the necessary data to learn the optimal policy.

There is on-going research to reduce the amount of data and time required to learn the optimal policy but when deploying robots in the real world, it remains extremely challenging to pre-program them for specific end-user applications.
%these solutions become cost-expensive and inefficient to adapt to user-specific tasks.
Robots are currently being used for many industrial applications from welding (arc welding, spot welding, \etc) to material handling (pick and place, packaging, palletizing, \etc).
Furthermore, there exist a wide range of robot grippers (claw, suction, magnetic, \etc) that are dependent on the robot platform.
Instead of developing robots for domain-specific tasks, a more flexible solution is to have robots learn new actions directly from end-users and let them customise the robot for their specific application.

A feasible programming system could involve a human operator teach the robot new tasks and have the robot automatically generalise the taught action to new scenarios.
Programming by Demonstration (PbD) allows end-users to teach the robot new tasks by taking demonstrations as input and inferring the goal or a policy for the task.
Thus, the robot can be taught a user-specific task with minimal programming overhead and independent of the robot's architecture.
However, existing PbD solutions usually require users to teach robots an action sequence, which they believe is the optimal solution to achieve a certain goal.
If the goal changes, the user has to come up with a new solution and teach the robot again.

%\textbf{Reusable actions.}
% teaching action semantics
Current approaches only teach the robot an action for a specific task, but do not explicitly associate a semantic meaning to it.
For example, conditions for executing a pick and place action (\eg to grab an object only if the gripper is empty) are generally neglected during the demonstration.
If the robot is taught an action's semantic meaning, \ie the conditions for executing the action, it could reuse the action in a different context.
%If the teacher demonstrates a pick-up action to the robot, there is no mention of communicating the conditions for when it can execute the action.
%The user could select task execution plans via a user interface (\cite{guerin2015framework}), but ideally, the robot should deduce a task execution plan for a given goal autonomously. 
%In this thesis we focus on teaching robots material handling tasks, in particular pick and place tasks.
In this thesis we argue for teaching robots atomic actions with their semantic meanings, instead of entire action sequences, and delegating the logical reasoning process of finding a solution to task planners.
To that end, we consider two aspects:

\textbf{Teaching atomic actions.}
Existing PbD implementations are task-specific and cannot be applied to previously unseen scenarios.
Many PbD implementations already have pick and place actions coded into the system (\cite{veeraraghavan2008teaching}) and the robot is taught an action sequence to achieve a predefined goal.
Even slight changes in the goal could require a different action sequence, so the robot needs to be taught the new action sequence.
This highlights a key issue in PbD, namely, to design a system that allows the robot to learn  generic tasks that are applicable to different scenarios.
In this work, we assume that the robot does not have any atomic actions preprogrammed.
We want to allow the user to teach atomic actions from scratch.

\textbf{Automatic action sequence generation.}
After having learned all atomic actions, the robot should be able to reuse these actions  to solve previously unseen tasks.
Current solutions either teach the robot entire action sequences or include an intermediate manual step where the user has to construct an optimal sequences.
Finding an optimal solution can be tedious, expensive, or even computationally impossible for humans (\eg for solving a rubik's cube).
Instead, we want to delegate the logical reasoning process of finding a solution to state-of-the-art task planners, thus facilitating the programming process for the human operator.
%We want to equip the robot with all the skills needed to act autonomously in any state of the world, rather than teaching it how to react to a given state of the world.
%To achieve this, we have to design our framework using plans, which provides us with the required tools.
%As we focus on collaborative environments, where the teacher is actively involved in the learning process, plans allow a means to communicate the teacher's intentions together with the demonstrations.
%We use Automated Planning techniques, to generate action sequences automatically.
%This will enable the robot to learn the action and its semantics, so that an action sequence can be generated automatically with the help of a planner. 
In the following chapter \ref{chap:Sota-AP} we will give an overview of Automated Planning.