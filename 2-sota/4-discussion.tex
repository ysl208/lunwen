\section{Discussions and Relations to Present Work}
The problem with manual programming systems is the need for programming expertise and high programming time and effort required to debug and test.
The solutions are often task-specific and cannot be changed easily by end-users.

Automatic programming systems require significantly less effort when it comes to the programming process. 
However, machine learning systems such as Neural Networks often need large amounts of training data and data that is relevant for the desired application scenario.
Reinforcement Learning solutions can be time-consuming as they require the robot to explore the environment and collect the necessary data to learn the optimal policy.
There is on-going research to reduce the amount of data and time required to learn the optimal policy.
When deploying robots in real world applications, both manual and machine learning systems become cost-expensive and inefficient to adapt to different tasks.
A feasible automatic programming system can involve a human operator teach the robot the desired tasks.

\subsection{Relation to Present Work}
In this thesis we use Programming by Demonstration (PbD) as an intuitive technique for teaching the robot new tasks with minimal programming overhead.
The problem we address is two-fold:
\paragraph{Teaching atomic actions}
In general, many robot PbD implementations already have pick and place actions coded into the system \cite{veeraraghavan2008teaching}.
Existing PbD implementations are rather task-specific and cannot be applied to arbitrary scenarios.
The robot is often taught an action sequence to achieve a predefined goal.
Even slight changes in the goal could require a different action sequence, so the robot needs to be taught the new action sequence.
This highlights a key issue in PbD, namely to design a generic system that allows the robot to learn tasks that are applicable to different scenarios.
In this work, we assume that the robot does not have any atomic actions preprogrammed.
The user should be able to teach the robot atomic actions by demonstration, which are required for the action sequence.

\paragraph{Automatic action sequence construction}
After having learned all atomic actions, the robot needs to reuse these actions to achieve a goal.
Current solutions either teach the robot entire action sequences or include an intermediate manual step where the user has to construct an optimal sequences.
Finding an optimal sequence can be tedious and expensive.
We want to equip the robot with all the skills needed to act autonomously in any state of the world, rather than teaching it how to react to a given state of the world.
%To achieve this, we have to design our framework using plans, which provides us with the required tools.
%As we focus on collaborative environments, where the teacher is actively involved in the learning process, plans allow a means to communicate the teacher's intentions together with the demonstrations.
Therefore, our policy derivation choice will enable the robot to learn the action, as well as its semantics, and combine them with goal-oriented problem-solving techniques.


% PbD + PDDL representation
In \cite{veeraraghavan2008teaching} the robot is taught a task-specific plan from sequential demonstrations and  learned actions are represented in PDDL with preconditions and effects.