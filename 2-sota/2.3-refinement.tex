\subsection{Interactive Policy Refinement Techniques}\label{subsec:Other RP Methods}
The robot can learn from observation data provided by the teacher (Learning by Observation), by self-exploration using a defined reward function (Learning by Exploration), or by interactive teaching from continuous feedback (Active Learning). In the following sections we will give an overview of these approaches.

\subsubsection{Active/Interactive Learning}\label{sssec:Active Learning} (\cite{chernova2014robot},\cite{calinon2007active})
 - teacher provides robot initial data, observes robot performance and provides feedback
     - robot can ask for feedback (\cite{cakmak2012aaai})
 - teacher can modify learned action using a visual interface (\cite{alexandrova2015roboflow})

 (\cite{nicolescu2003natural}) present a PbD approach, which allows the robot to learn skill representations and refine them by using feedback cues provided by the teacher.
Similarly, (\cite{calinon2007active}) and (\cite{calinon2007incremental}) implement systems, which actively involve the teacher in the robot's learning process, by providing human guidance to a humanoid robot. The robot first observes the demonstration performed by the teacher, who is wearing motion sensors. When it tries to reproduce the action, the teacher can refine the movement by physically moving its limbs.

